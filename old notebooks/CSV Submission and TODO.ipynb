{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important questions\n",
    "\n",
    "- how do i use image segmentation in conjunction with classification?\n",
    "\n",
    "- is it any better to train multiple binary classifiers instead of a multiclass CNN\n",
    "\n",
    "- apparently i can only use data augmentation if i do end-to-end? i guess i cant store too many augmented images in system memory but i can probably find a way around it\n",
    "\n",
    "TODO:\n",
    "\n",
    "- class weighting\n",
    "- fine tuning\n",
    "- xgboost\n",
    "- image cleaning: \n",
    "    - removing background? prob not gonna work\n",
    "    - lighting adjustment - read other papers\n",
    "    \n",
    "- single classifiers\n",
    "- progressive resizing\n",
    "- hyperparam search? (at the very end)\n",
    "\n",
    "DONE:\n",
    "- batch normalization <- only really for speedups\n",
    "    \n",
    "Findings:\n",
    "\n",
    "- data augmentation on underrepresented classes is better than just throwing everything at the model i guess thats obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "def loading_text(text):\n",
    "    sys.stdout.write(str(text) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load_img(img_name):\n",
    "    img = cv2.imread(os.path.join(img_dir, img_name), 1)\n",
    "    img = cv2.resize(img, dsize=(300,225))\n",
    "    img = img[1:, 38:-38]\n",
    "#     img = cv2.resize(img, dsize=(200,150))\n",
    "    return img\n",
    "\n",
    "def extract_features(X, batch_size, conv_base):\n",
    "    total = len(X)\n",
    "    output_shape = conv_base.layers[-1].output_shape[1:]\n",
    "    features = np.zeros(shape=(total,) + output_shape)\n",
    "    i = 0\n",
    "    while i*batch_size < total:\n",
    "        loading_text(str(i*batch_size) +  \"/\" + str(total))\n",
    "        inputs_batch = X[i*batch_size:(i+1)*batch_size]/255 # SCALING TO 0-1 HERE\n",
    "        features[i * batch_size : (i + 1) * batch_size] = conv_base.predict(inputs_batch)\n",
    "        i += 1\n",
    "    return features.reshape(total, np.prod(output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"data\\\\ISIC2018_Task3_Validation_Input\"\n",
    "img_names = np.array(os.listdir(img_dir))\n",
    "X_all = np.array([load_img(img_name) for img_name in img_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kevin\\documents\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications import VGG16\n",
    "# conv_base = VGG16(weights='imagenet',\n",
    "#                   include_top=False,\n",
    "#                   input_shape=(150, 200, 3))\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "conv_base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "#conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/193\r"
     ]
    }
   ],
   "source": [
    "X_f = extract_features(X_all, 32, conv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 62720)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Computes the recall over the whole batch using threshold_value.\n",
    "        \"\"\"\n",
    "        threshold_value = threshold\n",
    "        # Adaptation of the \"round()\" used before to get the predictions. Clipping to make sure that the predicted raw values are between 0 and 1.\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        # Compute the number of true positives. Rounding in prevention to make sure we have an integer.\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        # Compute the number of positive targets.\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models\\\\0003.h5\")#, custom_objects={'recall':recall_threshold()})\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(X_f)\n",
    "b = np.zeros_like(a)\n",
    "b[np.arange(len(a)), a.argmax(1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_csv(csv_name, img_names, Y_pred):\n",
    "    with open(csv_name, 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',', lineterminator='\\n',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(['image', 'MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC'])\n",
    "        for i in range(len(img_names)):\n",
    "            filewriter.writerow([img_names[i][:-4]] + Y_pred[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_csv('ISIC_2018_Validation.csv', img_names, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
