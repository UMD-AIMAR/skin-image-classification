{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def import_images(path, img_names):\n",
    "    imgs = [cv2.imread(os.path.join(path, img_name), 1) for img_name in img_names]\n",
    "    return np.array(resize_all(imgs))\n",
    "\n",
    "def import_target(path):\n",
    "    f = open(path)\n",
    "    lines = f.read().split('\\n')\n",
    "    toks = [line.split(',') for line in lines]\n",
    "    toks = toks[1:-1]\n",
    "    f.close()\n",
    "    return np.array([[int(tk) for tk in tok[1:]] for tok in toks])\n",
    "\n",
    "def resize_all(X):\n",
    "    return np.array([cv2.resize(x,dsize=(200,150)) for x in X])\n",
    "\n",
    "def class_indices(Y, j):\n",
    "    return [i for i in range(len(Y)) if Y[i][j] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_rand_state = random.getstate()\n",
    "np_rand_state = np.random.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"data\\\\ISIC2018_Task3_Training_Input\"\n",
    "target_path = \"data\\\\ISIC_2018_Training_GroundTruth.csv\"\n",
    "img_names, Y_all = np.array(os.listdir(img_path)), import_target(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1113, 6705,  514,  327, 1099,  115,  142])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = np.sum(Y_all, axis=0)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make batches a multiple of 7,\n",
    "feed in even # of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_n = 1400\n",
    "X, Y = np.zeros(shape=(7*c_n, 150, 200, 3)), np.zeros(shape=(7*c_n, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 7):\n",
    "    inds = class_indices(Y_all, j)[:c_n]\n",
    "    X_c = import_images(img_path, img_names[inds])\n",
    "    Y_c = Y_all[inds]\n",
    "    i = len(inds)\n",
    "    X[c_n*j:c_n*j+i] = X_c\n",
    "    Y[c_n*j:c_n*j+i] = Y_c   \n",
    "    if i < c_n:  \n",
    "        for x_new, y_new in datagen.flow(X_c, Y_c, batch_size=1):\n",
    "            X[c_n*j+i] = x_new\n",
    "            Y[c_n*j+i] = y_new\n",
    "            i += 1\n",
    "            if i == c_n:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400. 1400. 1400. 1400. 1400. 1400. 1400.]\n",
      "(9800, 150, 200, 3) (9800, 7)\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y, axis=0))\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kevin\\documents\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 200, 3))\n",
    "\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "# conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 200, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_text(text):\n",
    "    sys.stdout.write(str(text) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def extract_features(X, batch_size, conv_base):\n",
    "    total = len(X)\n",
    "    output_shape = conv_base.layers[-1].output_shape[1:]\n",
    "    features = np.zeros(shape=(total,) + output_shape)\n",
    "    i = 0\n",
    "    while i*batch_size < total:\n",
    "        loading_text(str(i*batch_size) +  \"/\" + str(total))\n",
    "        inputs_batch = X[i*batch_size:(i+1)*batch_size]/255 # SCALING TO 0-1 HERE\n",
    "        features[i * batch_size : (i + 1) * batch_size] = conv_base.predict(inputs_batch)\n",
    "        i += 1\n",
    "    return features.reshape(total, np.prod(output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9792/9800\r"
     ]
    }
   ],
   "source": [
    "X_f = extract_features(X, 32, conv_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('VGG_XY_' + str(c_n) + '.pkl', 'wb')\n",
    "pickle.dump((X_f,Y), file)\n",
    "# file = open('VGG_8750_XY_2.pkl', 'rb')\n",
    "# X_f, Y = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_f, Y,\n",
    "                                                stratify=Y, \n",
    "                                                test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8820, 12288), (980, 12288), (8820, 7), (980, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(Y_train, axis=0), np.sum(Y_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def precision_threshold(threshold=0.5):\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Computes the precision over the whole batch using threshold_value.\n",
    "        \"\"\"\n",
    "        threshold_value = threshold\n",
    "        # Adaptation of the \"round()\" used before to get the predictions. Clipping to make sure that the predicted raw values are between 0 and 1.\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        # Compute the number of true positives. Rounding in prevention to make sure we have an integer.\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        # count the predicted positives\n",
    "        predicted_positives = K.sum(y_pred)\n",
    "        # Get the precision ratio\n",
    "        precision_ratio = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision_ratio\n",
    "    return precision\n",
    "\n",
    "def recall_threshold(threshold = 0.5):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Computes the recall over the whole batch using threshold_value.\n",
    "        \"\"\"\n",
    "        threshold_value = threshold\n",
    "        # Adaptation of the \"round()\" used before to get the predictions. Clipping to make sure that the predicted raw values are between 0 and 1.\n",
    "        y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())\n",
    "        # Compute the number of true positives. Rounding in prevention to make sure we have an integer.\n",
    "        true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))\n",
    "        # Compute the number of positive targets.\n",
    "        possible_positives = K.sum(K.clip(y_true, 0, 1))\n",
    "        recall_ratio = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall_ratio\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8820 samples, validate on 980 samples\n",
      "Epoch 1/40\n",
      "8820/8820 [==============================] - 50s 6ms/step - loss: 2.1449 - acc: 0.4319 - recall: 0.2461 - val_loss: 1.1418 - val_acc: 0.5796 - val_recall: 0.3459\n",
      "\n",
      "Epoch 00001: val_recall improved from -inf to 0.34592, saving model to models\\vgg16_train1260\\epoch01_acc0.58.hdf5\n",
      "Epoch 2/40\n",
      "8820/8820 [==============================] - 51s 6ms/step - loss: 1.1861 - acc: 0.5574 - recall: 0.3943 - val_loss: 1.1747 - val_acc: 0.5837 - val_recall: 0.4102\n",
      "\n",
      "Epoch 00002: val_recall improved from 0.34592 to 0.41020, saving model to models\\vgg16_train1260\\epoch02_acc0.58.hdf5\n",
      "Epoch 3/40\n",
      "8820/8820 [==============================] - 54s 6ms/step - loss: 1.0774 - acc: 0.5978 - recall: 0.4562 - val_loss: 1.0250 - val_acc: 0.6112 - val_recall: 0.4510\n",
      "\n",
      "Epoch 00003: val_recall improved from 0.41020 to 0.45102, saving model to models\\vgg16_train1260\\epoch03_acc0.61.hdf5\n",
      "Epoch 4/40\n",
      "8820/8820 [==============================] - 73s 8ms/step - loss: 0.9946 - acc: 0.6356 - recall: 0.5095 - val_loss: 0.9469 - val_acc: 0.6327 - val_recall: 0.5000\n",
      "\n",
      "Epoch 00004: val_recall improved from 0.45102 to 0.50000, saving model to models\\vgg16_train1260\\epoch04_acc0.63.hdf5\n",
      "Epoch 5/40\n",
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.9226 - acc: 0.6562 - recall: 0.5519 - val_loss: 1.0252 - val_acc: 0.6133 - val_recall: 0.5449\n",
      "\n",
      "Epoch 00005: val_recall improved from 0.50000 to 0.54490, saving model to models\\vgg16_train1260\\epoch05_acc0.61.hdf5\n",
      "Epoch 6/40\n",
      "8820/8820 [==============================] - 83s 9ms/step - loss: 0.8678 - acc: 0.6783 - recall: 0.5825 - val_loss: 1.0416 - val_acc: 0.6224 - val_recall: 0.5265\n",
      "\n",
      "Epoch 00006: val_recall did not improve from 0.54490\n",
      "Epoch 7/40\n",
      "8820/8820 [==============================] - 84s 10ms/step - loss: 0.8219 - acc: 0.6960 - recall: 0.6079 - val_loss: 1.1009 - val_acc: 0.5735 - val_recall: 0.4847\n",
      "\n",
      "Epoch 00007: val_recall did not improve from 0.54490\n",
      "Epoch 8/40\n",
      "8820/8820 [==============================] - 82s 9ms/step - loss: 0.7847 - acc: 0.7083 - recall: 0.6314 - val_loss: 1.0000 - val_acc: 0.6316 - val_recall: 0.5143\n",
      "\n",
      "Epoch 00008: val_recall did not improve from 0.54490\n",
      "Epoch 9/40\n",
      "8820/8820 [==============================] - 83s 9ms/step - loss: 0.7552 - acc: 0.7207 - recall: 0.6486 - val_loss: 1.1193 - val_acc: 0.6408 - val_recall: 0.5980\n",
      "\n",
      "Epoch 00009: val_recall improved from 0.54490 to 0.59796, saving model to models\\vgg16_train1260\\epoch09_acc0.64.hdf5\n",
      "Epoch 10/40\n",
      "8820/8820 [==============================] - 77s 9ms/step - loss: 0.7313 - acc: 0.7361 - recall: 0.6673 - val_loss: 0.9720 - val_acc: 0.6602 - val_recall: 0.5949\n",
      "\n",
      "Epoch 00010: val_recall did not improve from 0.59796\n",
      "Epoch 11/40\n",
      "8820/8820 [==============================] - 82s 9ms/step - loss: 0.6941 - acc: 0.7393 - recall: 0.6793 - val_loss: 1.1757 - val_acc: 0.6051 - val_recall: 0.5418\n",
      "\n",
      "Epoch 00011: val_recall did not improve from 0.59796\n",
      "Epoch 12/40\n",
      "8820/8820 [==============================] - 90s 10ms/step - loss: 0.6582 - acc: 0.7596 - recall: 0.7000 - val_loss: 1.1131 - val_acc: 0.6071 - val_recall: 0.5490\n",
      "\n",
      "Epoch 00012: val_recall did not improve from 0.59796\n",
      "Epoch 13/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.6483 - acc: 0.7569 - recall: 0.7020 - val_loss: 1.0964 - val_acc: 0.6561 - val_recall: 0.5939\n",
      "\n",
      "Epoch 00013: val_recall did not improve from 0.59796\n",
      "Epoch 14/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.6168 - acc: 0.7732 - recall: 0.7268 - val_loss: 1.0336 - val_acc: 0.6929 - val_recall: 0.6337\n",
      "\n",
      "Epoch 00014: val_recall improved from 0.59796 to 0.63367, saving model to models\\vgg16_train1260\\epoch14_acc0.69.hdf5\n",
      "Epoch 15/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.5998 - acc: 0.7783 - recall: 0.7307 - val_loss: 1.1027 - val_acc: 0.6551 - val_recall: 0.5969\n",
      "\n",
      "Epoch 00015: val_recall did not improve from 0.63367\n",
      "Epoch 16/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.5774 - acc: 0.7900 - recall: 0.7415 - val_loss: 1.1176 - val_acc: 0.6704 - val_recall: 0.6163\n",
      "\n",
      "Epoch 00016: val_recall did not improve from 0.63367\n",
      "Epoch 17/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.5612 - acc: 0.7941 - recall: 0.7492 - val_loss: 1.1064 - val_acc: 0.6714 - val_recall: 0.6255\n",
      "\n",
      "Epoch 00017: val_recall did not improve from 0.63367\n",
      "Epoch 18/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.5557 - acc: 0.8033 - recall: 0.7624 - val_loss: 1.2299 - val_acc: 0.6541 - val_recall: 0.6173\n",
      "\n",
      "Epoch 00018: val_recall did not improve from 0.63367\n",
      "Epoch 19/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.5361 - acc: 0.8066 - recall: 0.7680 - val_loss: 1.3056 - val_acc: 0.6490 - val_recall: 0.6092\n",
      "\n",
      "Epoch 00019: val_recall did not improve from 0.63367\n",
      "Epoch 20/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.5213 - acc: 0.8127 - recall: 0.7763 - val_loss: 1.1291 - val_acc: 0.6857 - val_recall: 0.6398\n",
      "\n",
      "Epoch 00020: val_recall improved from 0.63367 to 0.63980, saving model to models\\vgg16_train1260\\epoch20_acc0.69.hdf5\n",
      "Epoch 21/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.5026 - acc: 0.8166 - recall: 0.7824 - val_loss: 1.1976 - val_acc: 0.6806 - val_recall: 0.6347\n",
      "\n",
      "Epoch 00021: val_recall did not improve from 0.63980\n",
      "Epoch 22/40\n",
      "8820/8820 [==============================] - 88s 10ms/step - loss: 0.4966 - acc: 0.8266 - recall: 0.7906 - val_loss: 1.3361 - val_acc: 0.6684 - val_recall: 0.6398\n",
      "\n",
      "Epoch 00022: val_recall improved from 0.63980 to 0.63980, saving model to models\\vgg16_train1260\\epoch22_acc0.67.hdf5\n",
      "Epoch 23/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.4711 - acc: 0.8294 - recall: 0.7971 - val_loss: 1.3805 - val_acc: 0.6684 - val_recall: 0.6276\n",
      "\n",
      "Epoch 00023: val_recall did not improve from 0.63980\n",
      "Epoch 24/40\n",
      "8820/8820 [==============================] - 88s 10ms/step - loss: 0.4809 - acc: 0.8270 - recall: 0.7988 - val_loss: 1.1924 - val_acc: 0.6786 - val_recall: 0.6163\n",
      "\n",
      "Epoch 00024: val_recall did not improve from 0.63980\n",
      "Epoch 25/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.4635 - acc: 0.8367 - recall: 0.8063 - val_loss: 1.2171 - val_acc: 0.6735 - val_recall: 0.6357\n",
      "\n",
      "Epoch 00025: val_recall did not improve from 0.63980\n",
      "Epoch 26/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.4583 - acc: 0.8382 - recall: 0.8118 - val_loss: 1.2436 - val_acc: 0.6673 - val_recall: 0.6296\n",
      "\n",
      "Epoch 00026: val_recall did not improve from 0.63980\n",
      "Epoch 27/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.4468 - acc: 0.8399 - recall: 0.8152 - val_loss: 1.4251 - val_acc: 0.6806 - val_recall: 0.6541\n",
      "\n",
      "Epoch 00027: val_recall improved from 0.63980 to 0.65408, saving model to models\\vgg16_train1260\\epoch27_acc0.68.hdf5\n",
      "Epoch 28/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.4406 - acc: 0.8418 - recall: 0.8137 - val_loss: 1.3833 - val_acc: 0.6694 - val_recall: 0.6357\n",
      "\n",
      "Epoch 00028: val_recall did not improve from 0.65408\n",
      "Epoch 29/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.4244 - acc: 0.8473 - recall: 0.8228 - val_loss: 1.3285 - val_acc: 0.6582 - val_recall: 0.6337\n",
      "\n",
      "Epoch 00029: val_recall did not improve from 0.65408\n",
      "Epoch 30/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.4276 - acc: 0.8514 - recall: 0.8262 - val_loss: 1.5066 - val_acc: 0.6551 - val_recall: 0.6255\n",
      "\n",
      "Epoch 00030: val_recall did not improve from 0.65408\n",
      "Epoch 31/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.4176 - acc: 0.8536 - recall: 0.8300 - val_loss: 1.5098 - val_acc: 0.6673 - val_recall: 0.6480\n",
      "\n",
      "Epoch 00031: val_recall did not improve from 0.65408\n",
      "Epoch 32/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.4045 - acc: 0.8599 - recall: 0.8364 - val_loss: 1.5422 - val_acc: 0.6571 - val_recall: 0.6378\n",
      "\n",
      "Epoch 00032: val_recall did not improve from 0.65408\n",
      "Epoch 33/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.4008 - acc: 0.8570 - recall: 0.8339 - val_loss: 1.5030 - val_acc: 0.6633 - val_recall: 0.6490\n",
      "\n",
      "Epoch 00033: val_recall did not improve from 0.65408\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.3868 - acc: 0.8636 - recall: 0.8431 - val_loss: 1.3687 - val_acc: 0.6776 - val_recall: 0.6347\n",
      "\n",
      "Epoch 00034: val_recall did not improve from 0.65408\n",
      "Epoch 35/40\n",
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.3800 - acc: 0.8677 - recall: 0.8473 - val_loss: 1.5973 - val_acc: 0.6724 - val_recall: 0.6510\n",
      "\n",
      "Epoch 00035: val_recall did not improve from 0.65408\n",
      "Epoch 36/40\n",
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.3852 - acc: 0.8694 - recall: 0.8488 - val_loss: 1.7493 - val_acc: 0.6398 - val_recall: 0.6255\n",
      "\n",
      "Epoch 00036: val_recall did not improve from 0.65408\n",
      "Epoch 37/40\n",
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.3672 - acc: 0.8755 - recall: 0.8576 - val_loss: 1.5336 - val_acc: 0.6765 - val_recall: 0.6551\n",
      "\n",
      "Epoch 00037: val_recall improved from 0.65408 to 0.65510, saving model to models\\vgg16_train1260\\epoch37_acc0.68.hdf5\n",
      "Epoch 38/40\n",
      "8820/8820 [==============================] - 85s 10ms/step - loss: 0.3691 - acc: 0.8724 - recall: 0.8511 - val_loss: 1.4771 - val_acc: 0.6806 - val_recall: 0.6643\n",
      "\n",
      "Epoch 00038: val_recall improved from 0.65510 to 0.66429, saving model to models\\vgg16_train1260\\epoch38_acc0.68.hdf5\n",
      "Epoch 39/40\n",
      "8820/8820 [==============================] - 86s 10ms/step - loss: 0.3648 - acc: 0.8749 - recall: 0.8573 - val_loss: 1.5390 - val_acc: 0.6816 - val_recall: 0.6622\n",
      "\n",
      "Epoch 00039: val_recall did not improve from 0.66429\n",
      "Epoch 40/40\n",
      "8820/8820 [==============================] - 87s 10ms/step - loss: 0.3589 - acc: 0.8762 - recall: 0.8578 - val_loss: 1.7517 - val_acc: 0.6612 - val_recall: 0.6408\n",
      "\n",
      "Epoch 00040: val_recall did not improve from 0.66429\n",
      "Train on 8820 samples, validate on 980 samples\n",
      "Epoch 1/40\n",
      "1080/8820 [==>...........................] - ETA: 1:24 - loss: 6.3796 - acc: 0.2250 - recall: 0.1741"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c429c217501b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                   metrics=['accuracy', recall_threshold(0.5)])\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\documents\\venv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\kevin\\documents\\venv\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\documents\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\documents\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kevin\\documents\\venv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "ms = []\n",
    "hs = []\n",
    "for i in range(3):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(512, activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    filepath=\"models\\\\vgg16_train1260\\\\m{i:1d}_e{epoch:02d}_acc{val_acc:.2f}.h5\"\n",
    "    # monitor = 'val_acc'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_recall', verbose=1, save_best_only=True, mode='max')\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy', recall_threshold(0.5)])\n",
    "    history = model.fit(X_train, Y_train, epochs=40, batch_size=20, validation_data=(X_test, Y_test), callbacks=[checkpoint])\n",
    "    \n",
    "    ms.append(model)\n",
    "    hs.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can also try:\n",
    "- relu -> dropout\n",
    "- batch norm -> relu\n",
    "- batch norm -> relu -> dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def report(model, X_test, Y_test):\n",
    "    a = model.predict(X_test)\n",
    "    print(\"ROC AUC:\", roc_auc_score(Y_test, a))\n",
    "    b = np.zeros_like(a) # lol so this was it all along\n",
    "    b[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    print(classification_report(Y_test, b))\n",
    "    \n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ms:\n",
    "    report(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.921036807580175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60       140\n",
      "           1       0.75      0.72      0.73       140\n",
      "           2       0.55      0.66      0.60       140\n",
      "           3       0.66      0.59      0.63       140\n",
      "           4       0.62      0.47      0.53       140\n",
      "           5       0.71      0.79      0.75       140\n",
      "           6       0.95      0.89      0.92       140\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       980\n",
      "   macro avg       0.69      0.68      0.68       980\n",
      "weighted avg       0.69      0.68      0.68       980\n",
      " samples avg       0.68      0.68      0.68       980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "path = \"models\\\\vgg16_train1260\\\\\"\n",
    "model = load_model(path + \"epoch38_acc0.68.hdf5\", custom_objects={'recall':recall_threshold()})\n",
    "report(model, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
