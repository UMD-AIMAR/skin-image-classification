{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "img_dir = \"data/ISIC2018_Task3_Training_Input\"\n",
    "trg_dir = \"data/ISIC2018_Task3_Training_GroundTruth.csv\"\n",
    "\n",
    "def load_img(img_name):\n",
    "    img = cv2.imread(os.path.join(img_dir, img_name), 1)\n",
    "    img = cv2.resize(img, dsize=(200,150))\n",
    "    return img\n",
    "\n",
    "def load_target():\n",
    "    f = open(trg_dir)\n",
    "    lines = f.read().split('\\n')\n",
    "    toks = [line.split(',') for line in lines]\n",
    "    toks = toks[1:-1]\n",
    "    f.close()\n",
    "    return np.array([[int(float(tk)) for tk in tok[1:]] for tok in toks])\n",
    "\n",
    "def class_indices(Y, j):\n",
    "    return [i for i in range(len(Y)) if Y[i][j] == 1]\n",
    "\n",
    "def loading_text(text):\n",
    "    sys.stdout.write(str(text) + '\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z, Y = np.array(sorted(os.listdir(img_dir))), load_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# conv_base = VGG16(include_top=False, weights='imagenet', input_shape=(150, 200, 3))\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "conv_base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(150, 200, 3))\n",
    "# from keras.applications import ResNet50\n",
    "# conv_base = ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3))\n",
    "\n",
    "output_len = np.prod(conv_base.layers[-1].output_shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take v_n instances from each class\n",
    "I_class = [np.array(class_indices(Y,j)) for j in range(7)]\n",
    "Y_class = [Y[i_class] for i_class in I_class]\n",
    "Z_class = [Z[i_class] for i_class in I_class]\n",
    "\n",
    "v_n = 20\n",
    "def split_YZ_class(Y_class, Z_class, n):\n",
    "    ### shuffler\n",
    "    for i in range(len(Y_class)):\n",
    "        inds = np.random.permutation(len(Y_class[i]))\n",
    "        Y_class[i], Z_class[i] = Y_class[i][inds], Z_class[i][inds]\n",
    "    Y_class_train, Z_class_train = [y_class[n:] for y_class in Y_class], [z_class[n:] for z_class in Z_class]\n",
    "    Y_class_valid, Z_class_valid = [y_class[:n] for y_class in Y_class], [z_class[:n] for z_class in Z_class]\n",
    "    return Y_class_train, Z_class_train, Y_class_valid, Z_class_valid\n",
    "\n",
    "# all of these are lists of numpy arrays until we manipulate them further\n",
    "Y_class_train, Z_class_train, Y_class_valid, Z_class_valid = split_YZ_class(Y_class, Z_class, v_n)\n",
    "\n",
    "# generate even validation set\n",
    "Y_valid_f, Z_valid = np.concatenate(Y_class_valid), np.concatenate(Z_class_valid)\n",
    "X_valid = np.array([load_img(img_name) for img_name in Z_valid])/255\n",
    "X_valid_f = conv_base.predict(X_valid).reshape((len(X_valid), output_len))\n",
    "X_valid.shape, Y_valid_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug_gen = ImageDataGenerator(\n",
    "    rescale             = 1./255,\n",
    "    rotation_range      = 40,\n",
    "    width_shift_range   = 0.2,\n",
    "    height_shift_range  = 0.2,\n",
    "    shear_range         = 0.2,\n",
    "    zoom_range          = 0.2,\n",
    "    brightness_range    = (0.8, 1.2),\n",
    "    horizontal_flip     = True,\n",
    "    vertical_flip       = True,\n",
    "    fill_mode           = 'nearest')\n",
    "\n",
    "def img_gen(Y_class, Z_class, batch_size):\n",
    "    # shuffler\n",
    "    for i in range(7):\n",
    "        inds = np.random.permutation(len(Y_class[i]))\n",
    "        Y_class[i], Z_class[i] = Y_class[i][inds], Z_class[i][inds]\n",
    "    # splitting\n",
    "    n = batch_size // 7\n",
    "    i = 0\n",
    "    while True:\n",
    "        Y_batch = np.concatenate([y_class[(i % len(y_class)):(i % len(y_class)) + n] for y_class in Y_class])\n",
    "        Z_batch = np.concatenate([z_class[(i % len(z_class)):(i % len(z_class)) + n] for z_class in Z_class])\n",
    "        X_batch = np.array([load_img(img_name) for img_name in Z_batch])\n",
    "        for x in aug_gen.flow(X_batch, shuffle=False, batch_size=len(X_batch)):\n",
    "            X_batch = x\n",
    "            break\n",
    "        yield X_batch, Y_batch\n",
    "        i += n\n",
    "    \n",
    "# generates features through conv_base\n",
    "def feat_gen(Y_class, Z_class, batch_size):\n",
    "    # shuffler\n",
    "    for i in range(7):\n",
    "        inds = np.random.permutation(len(Y_class[i]))\n",
    "        Y_class[i], Z_class[i] = Y_class[i][inds], Z_class[i][inds]\n",
    "    # splitting\n",
    "    n = batch_size // 7\n",
    "    i = 0\n",
    "    while True:\n",
    "        Y_batch = np.concatenate([y_class[(i % len(y_class)):(i % len(y_class)) + n] for y_class in Y_class])\n",
    "        Z_batch = np.concatenate([z_class[(i % len(z_class)):(i % len(z_class)) + n] for z_class in Z_class])\n",
    "        X_batch = np.array([load_img(img_name) for img_name in Z_batch])\n",
    "        for x in aug_gen.flow(X_batch, shuffle=False, batch_size=len(X_batch)):\n",
    "            X_batch = np.reshape(conv_base.predict(x), (len(x), output_len)) # generate augmented versions of each img, then predict\n",
    "            break\n",
    "        yield X_batch, Y_batch\n",
    "        i += n\n",
    "        \n",
    "# Pre-generate convolutional features\n",
    "# N = 700\n",
    "# i = 0\n",
    "# b = 7\n",
    "# X_train_f = np.zeros(shape=(N, output_len))\n",
    "# Y_train_f = np.zeros(shape=(N, 7))\n",
    "# for X_batch, Y_batch in feat_gen(Y_class_train, Z_class_train, b):\n",
    "#     X_train_f[i:i+b] = X_batch\n",
    "#     Y_train_f[i:i+b] = Y_batch\n",
    "#     i += b\n",
    "#     loading_text(str(i) + \"/\" + str(N))\n",
    "#     if i >= N:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discard all features with zero variance, indices of remaining features are in nz\n",
    "# nz = []\n",
    "# i = 0  # counter\n",
    "# d = 50 # delta\n",
    "# while i < X_train_f.shape[1]:\n",
    "#     inds = i + np.nonzero(np.var(X_train_f[:, i:i+d], axis=0))[0]\n",
    "#     nz.append(inds)\n",
    "#     i += d\n",
    "#     loading_text(str(i) + \"/\" + str(X_train_f.shape[1]))\n",
    "# nz = np.concatenate(nz, axis=0)\n",
    "# len(nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually discard from X,Y\n",
    "# X_train_f2 = X_train_f[:,nz]\n",
    "# X_valid_f2 = X_valid_f[:,nz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.initializers import he_normal\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 28 # 14\n",
    "ms = []\n",
    "hs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try feature standarization\n",
    "# from sklearn import preprocessing\n",
    "# standardized_X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "def recall(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Computes the true positive rate.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "overfitCallback = EarlyStopping(monitor='recall', min_delta=0, patience = 50) #loss\n",
    "\n",
    "ms, hs = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit this to use img_gen instead of feature_genfst\n",
    "c\n",
    "N = [512]\n",
    "for n in N:\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(n, activation='relu', input_shape=(output_len,)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(7, activation='softmax'))\n",
    "    model.compile(optimizer=optimizers.Adam(lr=0.00002), # even slower learning rate?\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc', recall])\n",
    "    history = model.fit_generator(feat_gen(Y_class_train, Z_class_train, batch_size),\n",
    "                        steps_per_epoch=200,\n",
    "                        epochs=2000, \n",
    "                        validation_data=(X_valid_f, Y_valid_f), \n",
    "                        callbacks=[overfitCallback],\n",
    "                        verbose=1)\n",
    "    ms.append(model)\n",
    "    hs.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms[1].save(\"models/vgg1536.h5\")\n",
    "predictor = models.load_model(\"models/vgg1536.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning vgg\n",
    "conv_base = VGG16(include_top=False, weights='imagenet', input_shape=(150, 200, 3))\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tuned_model = models.Sequential()\n",
    "tuned_model.add(conv_base)\n",
    "tuned_model.add(layers.Flatten())\n",
    "tuned_model.add(predictor)\n",
    "tuned_model.compile(optimizer=optimizers.Adam(lr=0.00001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "tuned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitCallback_ft = EarlyStopping(monitor='loss', min_delta=0, patience = 5)\n",
    "history = tuned_model.fit_generator(img_gen(Y_class_train, Z_class_train, batch_size),\n",
    "    steps_per_epoch=10,\n",
    "    epochs=20, \n",
    "    validation_data=(X_valid, Y_valid_f), \n",
    "    callbacks=[overfitCallback_ft],\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model.save(\"models/vgg1536_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def pred_max(model, X_test):\n",
    "    a = model.predict(X_test)\n",
    "    b = np.zeros_like(a) # lol so this was it all along\n",
    "    b[np.arange(len(a)), a.argmax(1)] = 1\n",
    "    return b\n",
    "\n",
    "def report(model, X_test, Y_test):\n",
    "    b = pred_max(model, X_test)\n",
    "    print(\"Area Under ROC:\", roc_auc_score(Y_test, b))\n",
    "    print(classification_report(Y_test, b))\n",
    "    \n",
    "    \n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'ro', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'ro', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"models/vgg1536.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report(model, X_valid_f, Y_valid_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
